{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('train_label.csv', dtype=str)\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".png\"\n",
    "\n",
    "traindf[\"ID\"]=traindf[\"ID\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 873 validated image filenames belonging to 3 classes.\n",
      "Found 291 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batchsize = 100\n",
    "val_batchsize = 10\n",
    "\n",
    "# datagen = ImageDataGenerator()\n",
    "datagen = ImageDataGenerator(validation_split=0.25)\n",
    "        \n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = traindf,\n",
    "    directory = \"train_image/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Label\",\n",
    "    subset = \"training\",\n",
    "    batch_size = train_batchsize,\n",
    "#     seed = 23,\n",
    "#     shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (512,512)\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = traindf,\n",
    "    directory = \"train_image/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Label\",\n",
    "    subset = \"validation\",\n",
    "    batch_size = val_batchsize,\n",
    "#     seed = 23,\n",
    "#     shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (512,512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    \"test_image\", \n",
    "#     batch_size = batch_size, \n",
    "    class_mode=None, \n",
    "    shuffle=False,\n",
    "    target_size = (512,512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(512, 512, 3))\n",
    "\n",
    "base_model = VGG19(include_top = False,\n",
    "    weights=\"imagenet\",\n",
    "#     input_tensor = input_tensor,\n",
    "    input_shape = (512, 512, 3),\n",
    "#     pooling = None,\n",
    "#     classes = 2,\n",
    "    classifier_activation = \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 16, 16, 512)       20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              134218752 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 154,246,211\n",
      "Trainable params: 134,221,827\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-bb69ac51b3cd>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 497s 62s/step - loss: 611.5194 - accuracy: 0.6300 - val_loss: 15.0213 - val_accuracy: 0.8655\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 453s 57s/step - loss: 21.1385 - accuracy: 0.8525 - val_loss: 10.4537 - val_accuracy: 0.8759\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 478s 60s/step - loss: 2.3244 - accuracy: 0.9521 - val_loss: 7.2454 - val_accuracy: 0.8931\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 487s 61s/step - loss: 7.6796 - accuracy: 0.9004 - val_loss: 14.5420 - val_accuracy: 0.8379\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 477s 60s/step - loss: 1.1196 - accuracy: 0.9754 - val_loss: 4.7108 - val_accuracy: 0.9103\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 434s 54s/step - loss: 0.3778 - accuracy: 0.9793 - val_loss: 2.9399 - val_accuracy: 0.9310\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 442s 55s/step - loss: 0.9976 - accuracy: 0.9767 - val_loss: 4.1056 - val_accuracy: 0.8931\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 2660s 333s/step - loss: 0.6178 - accuracy: 0.9767 - val_loss: 3.0573 - val_accuracy: 0.9276\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 10205s 1276s/step - loss: 0.3143 - accuracy: 0.9845 - val_loss: 13.3239 - val_accuracy: 0.8448\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 459s 57s/step - loss: 0.9438 - accuracy: 0.9806 - val_loss: 39.5167 - val_accuracy: 0.7552\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 461s 58s/step - loss: 23.2746 - accuracy: 0.8396 - val_loss: 15.9350 - val_accuracy: 0.8345\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 447s 56s/step - loss: 0.8135 - accuracy: 0.9780 - val_loss: 7.3539 - val_accuracy: 0.9103\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 451s 56s/step - loss: 1.2549 - accuracy: 0.9793 - val_loss: 7.9959 - val_accuracy: 0.9103\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 431s 54s/step - loss: 0.4793 - accuracy: 0.9948 - val_loss: 5.8154 - val_accuracy: 0.9241\n",
      "Epoch 15/50\n",
      "3/8 [==========>...................] - ETA: 2:13 - loss: 0.0560 - accuracy: 0.9963"
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "history = model.fit_generator(steps_per_epoch = train_generator.samples // train_generator.batch_size,\n",
    "                           generator = train_generator, \n",
    "                           validation_data = valid_generator, \n",
    "                           validation_steps = valid_generator.samples // valid_generator.batch_size,\n",
    "                           epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for plotting of the model results\n",
    "def visualize_results(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the function to illustrate accuracy and loss\n",
    "visualize_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(\n",
    "    test_generator,\n",
    "#     batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predicted.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"predicted.csv\", np.dstack((np.arange(prediction.size),prediction))[0],\"%d,%d\",header=\"ID,Label\",comments=\"\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
